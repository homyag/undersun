import os
import time
import re
from urllib.parse import urljoin, urlparse
from decimal import Decimal
import requests
from bs4 import BeautifulSoup
from django.core.management.base import BaseCommand
from django.core.files import File
from django.core.files.temp import NamedTemporaryFile
from django.utils.text import slugify
from django.contrib.auth.models import User
from django.utils import timezone
from apps.properties.models import Property, PropertyType, PropertyImage, Developer, Agent
from apps.locations.models import District, Location


class Command(BaseCommand):
    help = '–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ —Å —Å–∞–π—Ç–∞ undersunestate.com'

    def __init__(self):
        super().__init__()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.base_url = 'https://undersunestate.com'
        self.unknown_icons = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–∫–æ–Ω–æ–∫: {icon_name: count}

    def add_arguments(self, parser):
        parser.add_argument(
            '--type',
            type=str,
            choices=['all', 'villa', 'condo', 'townhouse', 'land', 'investment', 'business'],
            default='all',
            help='–¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞'
        )
        parser.add_argument(
            '--deal-type',
            type=str,
            choices=['all', 'buy', 'rent'],
            default='all',
            help='–¢–∏–ø —Å–¥–µ–ª–∫–∏ (–ø–æ–∫—É–ø–∫–∞/–∞—Ä–µ–Ω–¥–∞)'
        )
        parser.add_argument(
            '--test-single',
            type=str,
            help='–ü–∞—Ä—Å–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –ø–æ URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è'
        )
        parser.add_argument(
            '--max-pages',
            type=int,
            default=5,
            help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞'
        )
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏'
        )

    def handle(self, *args, **options):
        self.verbose = options.get('verbose', False)

        if options['test_single']:
            self.parse_single_property(options['test_single'])
            return

        property_type = options['type']
        deal_type = options['deal_type']
        max_pages = options['max_pages']

        self.stdout.write(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: —Ç–∏–ø={property_type}, —Å–¥–µ–ª–∫–∞={deal_type}")

        # –ü–æ–ª—É—á–∞–µ–º URL –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        property_urls = self.get_property_urls(property_type, deal_type, max_pages)
        self.stdout.write(f"–ù–∞–π–¥–µ–Ω–æ {len(property_urls)} –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")

        success_count = 0
        error_count = 0
        duplicate_count = 0

        for i, url in enumerate(property_urls):
            self.stdout.write(f"–ü–∞—Ä—Å–∏–Ω–≥ {i+1}/{len(property_urls)}: {url}")
            try:
                property_obj = self.parse_single_property(url)
                if hasattr(self, '_is_duplicate') and self._is_duplicate:
                    duplicate_count += 1
                else:
                    success_count += 1

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)
            except Exception as e:
                error_count += 1
                self.stdout.write(self.style.ERROR(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}"))

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stdout.write(self.style.SUCCESS(f"\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–†–°–ò–ù–ì–ê ==="))
        self.stdout.write(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {success_count}")
        self.stdout.write(f"–ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_count}")
        self.stdout.write(f"–û—à–∏–±–æ–∫: {error_count}")
        self.stdout.write(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(property_urls)}")

    def get_property_urls(self, property_type, deal_type, max_pages):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ URL –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        catalog_urls = []

        if property_type == 'all':
            if deal_type == 'buy':
                catalog_urls = [f"{self.base_url}/ru/real-estate/buy"]
            elif deal_type == 'rent':
                catalog_urls = [f"{self.base_url}/ru/real-estate/rent"]
            else:
                catalog_urls = [f"{self.base_url}/ru/real-estate"]
        else:
            slug_options = self.get_type_slug_options(property_type, deal_type)
            catalog_urls = [f"{self.base_url}/ru/real-estate/{slug}".rstrip('/') for slug in slug_options]

        collected_urls = []

        for index, catalog_url in enumerate(catalog_urls):
            urls = self.collect_catalog_properties(catalog_url, max_pages)
            if urls:
                if index > 0:
                    self.stdout.write(
                        self.style.WARNING(
                            f"–û—Å–Ω–æ–≤–Ω–æ–π URL –∫–∞—Ç–∞–ª–æ–≥–∞ –≤–µ—Ä–Ω—É–ª 0 –æ–±—ä–µ–∫—Ç–æ–≤. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ '{catalog_url}'"
                        )
                    )
                collected_urls = urls
                break

        if not collected_urls:
            self.stdout.write(
                self.style.WARNING(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Ç–∏–ø–∞ '{property_type}' (—Ç–∏–ø —Å–¥–µ–ª–∫–∏: {deal_type})"
                )
            )

        return collected_urls

    def get_type_slug_options(self, property_type, deal_type):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö slug'–æ–≤ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞ –ø–æ —Ç–∏–ø—É/—Å–¥–µ–ª–∫–µ"""
        type_slug_map = {
            'villa': {
                'all': ['villa', 'villas'],
                'buy': ['villa', 'villas', 'villa-for-sale', 'villas-for-sale'],
                'rent': ['villa-for-rent', 'villas-for-rent', 'villa', 'villas'],
            },
            'condo': {
                'all': ['condo', 'condominium', 'apartments', 'apartment'],
                'buy': ['condo', 'condominium', 'condo-for-sale', 'condominiums-for-sale'],
                'rent': ['condo-for-rent', 'condominiums-for-rent', 'condo'],
            },
            'townhouse': {
                'all': ['townhouse', 'townhouses'],
                'buy': ['townhouse-for-sale', 'townhouses-for-sale', 'townhouse', 'townhouses'],
                'rent': ['townhouse-for-rent', 'townhouses-for-rent', 'townhouse', 'townhouses'],
            },
            'land': {
                'all': ['land', 'land-plot'],
                'buy': ['land', 'land-plot', 'land-for-sale'],
            },
            'investment': {
                'all': ['for-investment', 'investment'],
                'buy': ['for-investment', 'investment'],
            },
            'business': {
                'all': ['ready-made-business', 'business'],
                'buy': ['ready-made-business', 'business'],
                'rent': ['ready-made-business-for-rent', 'business-for-rent', 'ready-made-business'],
            },
        }

        slug_config = type_slug_map.get(property_type, {})
        if deal_type in slug_config:
            slugs = slug_config[deal_type]
        else:
            slugs = slug_config.get('all', [property_type])

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        unique_slugs = []
        for slug in slugs:
            if slug and slug not in unique_slugs:
                unique_slugs.append(slug)

        if not unique_slugs:
            unique_slugs = [property_type]

        return unique_slugs

    def collect_catalog_properties(self, catalog_url, max_pages):
        """–°–æ–±–∏—Ä–∞–µ—Ç URL –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞"""
        property_urls = []
        page_number = 1
        items_per_page = 20
        start_offset = 0

        while page_number <= max_pages:
            page_url = catalog_url if page_number == 1 else f"{catalog_url}?start={start_offset}"
            self.stdout.write(f"–ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number} (offset={start_offset}): {page_url}")

            try:
                response = self.session.get(page_url)
            except requests.RequestException as exc:
                self.stdout.write(
                    self.style.ERROR(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {exc}")
                )
                break

            if response.status_code != 200:
                self.stdout.write(
                    self.style.ERROR(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {response.status_code}")
                )
                break

            soup = BeautifulSoup(response.content, 'html.parser')
            page_properties = self.extract_properties_from_page(soup)

            if not page_properties:
                if page_number == 1:
                    self.stdout.write(self.style.WARNING("–ù–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤"))
                else:
                    self.stdout.write(
                        f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –ø—É—Å—Ç–∞—è, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü –∫–∞—Ç–∞–ª–æ–≥–∞"
                    )
                break

            new_properties = 0
            for property_url in page_properties:
                if property_url not in property_urls:
                    property_urls.append(property_url)
                    new_properties += 1

            self.stdout.write(
                f"–ù–∞–π–¥–µ–Ω–æ {new_properties} –Ω–æ–≤—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number}"
            )

            if len(page_properties) < items_per_page:
                self.stdout.write(
                    f"–ù–∞–π–¥–µ–Ω–æ {len(page_properties)} –æ–±—ä–µ–∫—Ç–æ–≤ (–º–µ–Ω—å—à–µ {items_per_page}), –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
                )
                break

            if new_properties == 0:
                self.stdout.write(
                    f"–í—Å–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} —É–∂–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º"
                )
                break

            start_offset += items_per_page
            page_number += 1
            time.sleep(0.5)

        if property_urls:
            self.stdout.write(
                f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(property_urls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ {page_number} —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö"
            )

        return property_urls

    def extract_properties_from_page(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç—ã —Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        property_urls = []

        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç—ã
        selectors = [
            'a[href*="/ru/real-estate/"]',
            '.property-card a',
            '.listing-item a',
            '.property-link',
            'a[href*="/property/"]'
        ]

        for selector in selectors:
            links = soup.select(selector)
            if links:
                for link in links:
                    href = link.get('href', '')
                    if self.is_valid_property_url(href):
                        full_url = urljoin(self.base_url, href)
                        if full_url not in property_urls:
                            property_urls.append(full_url)

                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –æ–±—ä–µ–∫—Ç—ã —Å –ø–µ—Ä–≤—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Ö
                if property_urls:
                    break

        return property_urls

    def has_next_page(self, soup, current_page):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
        # –ò—â–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        pagination_selectors = [
            '.pagination',
            '.pager',
            '.page-nav',
            '.uk-pagination'
        ]

        for selector in pagination_selectors:
            pagination = soup.select_one(selector)
            if pagination:
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                next_page = current_page + 1
                next_links = pagination.find_all('a', string=str(next_page))
                if next_links:
                    return True

                # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–î–∞–ª–µ–µ" –∏–ª–∏ "Next"
                next_buttons = pagination.find_all('a', string=re.compile(r'(–î–∞–ª–µ–µ|Next|>)', re.I))
                if next_buttons:
                    return True

        return False

    def is_valid_property_url(self, url):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –æ–±—ä–µ–∫—Ç–æ–º –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        if not url or '/ru/real-estate/' not in url:
            return False

        # URL –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å ID –æ–±—ä–µ–∫—Ç–∞ (—á–∏—Å–ª–æ –≤ –Ω–∞—á–∞–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞)
        path_parts = url.split('/')
        if len(path_parts) >= 4:
            last_part = path_parts[-1]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å ID –≤ –Ω–∞—á–∞–ª–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 450-1-bedroom-apartment...)
            if re.match(r'\d+-', last_part):
                return True

        return False

    def parse_single_property(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        response = self.session.get(url)
        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}")

        soup = BeautifulSoup(response.content, 'html.parser')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞
        data = self.extract_property_data(soup, url)

        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if self.verbose:
            self.stdout.write(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
            for key, value in data.items():
                if key not in ['description', 'images']:
                    self.stdout.write(f"  {key}: {value}")
            if 'description' in data:
                self.stdout.write(f"  description: {len(data['description'])} —Å–∏–º–≤–æ–ª–æ–≤")
            if 'images' in data:
                self.stdout.write(f"  images: {len(data['images'])} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç –≤ –ë–î
        property_obj = self.save_property(data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–æ–±—Å—Ç–≤–∞
        if data.get('features'):
            self.save_property_features(property_obj, data['features'])

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if data.get('images'):
            self.save_property_images(property_obj, data['images'])

        return property_obj

    def extract_property_data(self, soup, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        data = {'original_url': url}

        # –í–ê–ñ–ù–û: –£–¥–∞–ª—è–µ–º –±–ª–æ–∫–∏ "–ü–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è" –ü–ï–†–ï–î –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö
        self.remove_similar_properties_blocks(soup)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –¢–û–õ–¨–ö–û –∏–∑ <span class="id-rea" itemprop="sku">CN63</span>
        sku_element = soup.find('span', {'class': 'id-rea', 'itemprop': 'sku'})
        if sku_element:
            sku_text = sku_element.get_text().strip()
            # –ë–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å (CN63, VL123, –∏ —Ç.–¥.)
            if sku_text:
                data['legacy_id'] = sku_text
                if self.verbose:
                    self.stdout.write(f"  ‚úÖ –ù–∞–π–¥–µ–Ω legacy_id –≤ <span class='id-rea'>: {data['legacy_id']}")
            else:
                if self.verbose:
                    self.stdout.write(f"  ‚ö†Ô∏è  –≠–ª–µ–º–µ–Ω—Ç <span class='id-rea'> –Ω–∞–π–¥–µ–Ω, –Ω–æ –ø—É—Å—Ç–æ–π")
        else:
            if self.verbose:
                self.stdout.write(f"  ‚ö†Ô∏è  –≠–ª–µ–º–µ–Ω—Ç <span class='id-rea'> –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_element = soup.find('h1') or soup.select_one('.property-title') or soup.find('title')
        if title_element:
            data['title'] = title_element.get_text().strip()
        else:
            data['title'] = '–û–±—ä–µ–∫—Ç –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏'

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º slug
        data['slug'] = self.generate_slug(url, data['title'])

        # –û–ø–∏—Å–∞–Ω–∏–µ - –∏—â–µ–º –ø–æ itemprop="description"
        description_content, excerpt = self.extract_property_description(soup)
        data['description'] = description_content
        data['short_description'] = excerpt

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        self.extract_property_characteristics(soup, data)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–¥–æ–±—Å—Ç–≤–∞
        data['features'] = self.extract_property_features(soup)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
        self.extract_property_price(soup, data)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        data['images'] = self.extract_property_images(soup)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏ —Ä–∞–π–æ–Ω
        self.extract_property_type_and_location(soup, url, data)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        self.extract_property_coordinates(soup, data)

        return data

    def remove_similar_properties_blocks(self, soup):
        """–£–¥–∞–ª–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤ '–ü–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è' –∏–∑ DOM"""
        if self.verbose:
            self.stdout.write(f"  –£–¥–∞–ª–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")

        removed_count = 0

        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º "–ü–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è" –∏–ª–∏ "Similar offers"
        similar_headers = soup.find_all(['h2', 'h3', 'h4'], string=lambda text: text and ('–ø–æ—Ö–æ–∂–∏–µ' in text.lower() or 'similar' in text.lower()))

        for header in similar_headers:
            # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –±–ª–æ–∫ –ü–û–°–õ–ï –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–æ–±—ã—á–Ω–æ —ç—Ç–æ —Å–∞–º –±–ª–æ–∫ —Å –ø–æ—Ö–æ–∂–∏–º–∏)
            next_sibling = header.find_next_sibling()
            if next_sibling:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –±–ª–æ–∫ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
                property_links = next_sibling.select('a[href*="/real-estate/"]')
                if len(property_links) > 1:
                    if self.verbose:
                        self.stdout.write(f"    –£–¥–∞–ª—è–µ–º –±–ª–æ–∫ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {len(property_links)} –æ–±—ä–µ–∫—Ç–æ–≤")
                    next_sibling.decompose()
                    removed_count += 1

            # –£–¥–∞–ª—è–µ–º —Å–∞–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            header.decompose()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º –±–ª–æ–∫–∏ —Å –∫–ª–∞—Å—Å–∞–º–∏, —É–∫–∞–∑—ã–≤–∞—é—â–∏–º–∏ –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã
        similar_selectors = [
            '.similar-properties',
            '.related-properties',
            '[class*="similar"]',
            '[class*="related"]'
        ]

        for selector in similar_selectors:
            similar_blocks = soup.select(selector)
            for block in similar_blocks:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±–ª–æ–∫ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
                property_links = block.select('a[href*="/real-estate/"]')
                if len(property_links) > 1:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤
                    if self.verbose:
                        self.stdout.write(f"    –£–¥–∞–ª—è–µ–º –±–ª–æ–∫ '{selector}': {len(property_links)} –æ–±—ä–µ–∫—Ç–æ–≤")
                    block.decompose()
                    removed_count += 1

        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –±–ª–æ–∫–∏ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –æ–±—ä–µ–∫—Ç—ã (—ç—Ç–æ —è–≤–Ω–æ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        all_divs = soup.find_all(['div', 'section', 'article'])
        for div in all_divs:
            property_links = div.find_all('a', href=lambda href: href and '/real-estate/' in href and re.search(r'/\d+-', href))
            # –ï—Å–ª–∏ –≤ –±–ª–æ–∫–µ –±–æ–ª—å—à–µ 2 —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ä–∞–∑–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ - —ç—Ç–æ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if len(property_links) > 2:
                unique_links = set([link.get('href') for link in property_links])
                if len(unique_links) > 2:
                    if self.verbose:
                        self.stdout.write(f"    –£–¥–∞–ª—è–µ–º –±–ª–æ–∫ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏: {len(unique_links)} –æ–±—ä–µ–∫—Ç–æ–≤")
                    div.decompose()
                    removed_count += 1

        if self.verbose:
            self.stdout.write(f"  –£–¥–∞–ª–µ–Ω–æ –±–ª–æ–∫–æ–≤ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {removed_count}")

    def extract_property_description(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        content = ""
        excerpt = ""

        # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ itemprop="description"
        description_element = soup.find('div', {'itemprop': 'description'})

        if description_element:
            # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            for unwanted in description_element(['script', 'style', 'noscript']):
                unwanted.decompose()

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–Ω—É—Ç—Ä–∏ div —Å itemprop="description"
            text_content = ''

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, —Å–æ—Ö—Ä–∞–Ω—è—è HTML-—Ç–µ–≥–∏
            for element in description_element.descendants:
                if hasattr(element, 'name') and element.name:
                    # –≠—Ç–æ HTML-—ç–ª–µ–º–µ–Ω—Ç
                    if element.name in ['p', 'div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li', 'br', 'strong', 'b', 'em', 'i', 'u', 'span']:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω—ã–µ HTML-—Ç–µ–≥–∏ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        continue
                elif hasattr(element, 'string') and element.string and element.string.strip():
                    # –≠—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª
                    text_content += element.string.strip() + ' '

            # –ë–µ—Ä–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π HTML, –∏—Å–∫–ª—é—á–∞—è –≤–Ω–µ—à–Ω–∏–π div
            inner_elements = list(description_element.children)
            if inner_elements:
                content_parts = []
                for child in inner_elements:
                    if hasattr(child, 'name') and child.name:
                        # HTML-—ç–ª–µ–º–µ–Ω—Ç - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å —Ç–µ–≥–∞–º–∏
                        content_parts.append(str(child))
                    elif hasattr(child, 'string') and child.string and child.string.strip():
                        # –¢–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª - –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ
                        clean_text = child.string.strip()
                        if len(clean_text) > 10:
                            content_parts.append(f'<p>{clean_text}</p>')

                content = '\n'.join(content_parts)

            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —ç–ª–µ–º–µ–Ω—Ç
            if not content.strip():
                content = ''.join(str(child) for child in description_element.children if str(child).strip())

            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 300 —Å–∏–º–≤–æ–ª–æ–≤)
            clean_text = description_element.get_text(separator=' ', strip=True)
            if clean_text:
                if len(clean_text) > 297:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è "..."
                    excerpt = clean_text[:297] + '...'
                else:
                    excerpt = clean_text

        else:
            # Fallback - –∏—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥—Ä—É–≥–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
            fallback_selectors = [
                '.property-description',
                '.description',
                '.desc-rea',
                '.uk-panel.desc-rea',
                '[itemprop="description"]'
            ]

            for selector in fallback_selectors:
                element = soup.select_one(selector)
                if element:
                    # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
                    for unwanted in element(['script', 'style']):
                        unwanted.decompose()

                    content = str(element)
                    text_content = element.get_text(separator=' ', strip=True)
                    excerpt = text_content[:297] + '...' if len(text_content) > 297 else text_content
                    break

            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –∏—â–µ–º —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            if not content:
                paragraphs = soup.find_all('p')
                content_paragraphs = []
                for p in paragraphs:
                    text = p.get_text().strip()
                    if len(text) > 50:  # –¢–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                        content_paragraphs.append(str(p))
                        if len(content_paragraphs) >= 5:  # –ù–µ –±–æ–ª–µ–µ 5 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
                            break

                if content_paragraphs:
                    content = '\n'.join(content_paragraphs)
                    first_p_text = soup.find('p').get_text().strip() if soup.find('p') else ''
                    excerpt = first_p_text[:297] + '...' if len(first_p_text) > 297 else first_p_text

        return content, excerpt

    def extract_property_characteristics(self, soup, data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –æ–±—ä–µ–∫—Ç–∞"""
        # –ò—â–µ–º —Å–ø–∞–ª—å–Ω–∏ –∏ –≤–∞–Ω–Ω—ã–µ –∫–æ–º–Ω–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
        text = soup.get_text().lower()

        # –°–ø–∞–ª—å–Ω–∏ - —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
        bedroom_element = soup.find('div', {'class': 'el-meta'}, string=lambda t: t and '—Å–ø–∞–ª—å–Ω' in t.lower() or 'bedroom' in t.lower())
        if bedroom_element:
            bedroom_match = re.search(r'(\d+)', bedroom_element.get_text())
            if bedroom_match:
                data['bedrooms'] = int(bedroom_match.group(1))
                if self.verbose:
                    self.stdout.write(f"  –°–ø–∞–ª—å–Ω–∏ (–∏–∑ el-meta): {data['bedrooms']}")

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        if 'bedrooms' not in data:
            bedroom_patterns = [
                r'(\d+)\s*—Å–ø–∞–ª—å–Ω',
                r'(\d+)\s*bedroom',
                r'(\d+)\s*bed\b'
            ]
            for pattern in bedroom_patterns:
                match = re.search(pattern, text)
                if match:
                    data['bedrooms'] = int(match.group(1))
                    if self.verbose:
                        self.stdout.write(f"  –°–ø–∞–ª—å–Ω–∏ (–∏–∑ —Ç–µ–∫—Å—Ç–∞): {data['bedrooms']}")
                    break

        # –í–∞–Ω–Ω—ã–µ –∫–æ–º–Ω–∞—Ç—ã - –ü–†–ò–û–†–ò–¢–ï–¢ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º
        bathroom_element = soup.find('div', {'class': 'el-meta'}, string=lambda t: t and ('–≤–∞–Ω–Ω' in t.lower() or 'bathroom' in t.lower()))
        if bathroom_element:
            bathroom_match = re.search(r'(\d+)', bathroom_element.get_text())
            if bathroom_match:
                data['bathrooms'] = int(bathroom_match.group(1))
                if self.verbose:
                    self.stdout.write(f"  ‚úÖ –í–∞–Ω–Ω—ã–µ –∫–æ–º–Ω–∞—Ç—ã (–∏–∑ el-meta): {data['bathrooms']}")

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ el-meta, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ (–Ω–æ —ç—Ç–æ –º–µ–Ω–µ–µ –Ω–∞–¥–µ–∂–Ω–æ)
        if 'bathrooms' not in data:
            bathroom_patterns = [
                r'–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–Ω–∞—Ç:\s*(\d+)',
                r'(\d+)\s*–≤–∞–Ω–Ω',
                r'(\d+)\s*bathroom',
                r'(\d+)\s*bath\b'
            ]
            for pattern in bathroom_patterns:
                match = re.search(pattern, text)
                if match:
                    data['bathrooms'] = int(match.group(1))
                    if self.verbose:
                        self.stdout.write(f"  –í–∞–Ω–Ω—ã–µ –∫–æ–º–Ω–∞—Ç—ã (–∏–∑ —Ç–µ–∫—Å—Ç–∞): {data['bathrooms']}")
                    break

        # –ü–ª–æ—â–∞–¥—å –æ–±—â–∞—è - –∏—â–µ–º –∂–∏–ª—É—é –ø–ª–æ—â–∞–¥—å
        area_element = soup.find('div', {'class': 'el-meta'}, string=lambda t: t and ('–ø–ª–æ—â–∞–¥' in t.lower() or 'area' in t.lower()) and '—É—á–∞—Å—Ç–∫–∞' not in t.lower())
        if area_element:
            area_match = re.search(r'(\d+(?:\.\d+)?)', area_element.get_text())
            if area_match:
                data['area_total'] = Decimal(area_match.group(1))
                if self.verbose:
                    self.stdout.write(f"  –ü–ª–æ—â–∞–¥—å –æ–±—â–∞—è (–∏–∑ el-meta): {data['area_total']} –º¬≤")

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        if 'area_total' not in data:
            area_patterns = [
                r'(\d+(?:\.\d+)?)\s*–º¬≤',
                r'(\d+(?:\.\d+)?)\s*m¬≤',
                r'(\d+(?:\.\d+)?)\s*–∫–≤\.?\s*–º',
                r'(\d+(?:\.\d+)?)\s*sqm'
            ]
            for pattern in area_patterns:
                match = re.search(pattern, text)
                if match:
                    data['area_total'] = Decimal(match.group(1))
                    if self.verbose:
                        self.stdout.write(f"  –ü–ª–æ—â–∞–¥—å –æ–±—â–∞—è (–∏–∑ —Ç–µ–∫—Å—Ç–∞): {data['area_total']} –º¬≤")
                    break

        # –ü–ª–æ—â–∞–¥—å —É—á–∞—Å—Ç–∫–∞ - –∏—â–µ–º –≤ —Å–ø–∏—Å–∫–∞—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ
        land_patterns = [
            r'–ø–ª–æ—â–∞–¥—å —É—á–∞—Å—Ç–∫–∞:\s*(\d+(?:\.\d+)?)\s*(?:–∫–≤\.?\s*–º|–º¬≤|m¬≤)',
            r'land area:\s*(\d+(?:\.\d+)?)\s*(?:sq\.?\s*m|m¬≤)',
            r'—É—á–∞—Å—Ç–∫–∞:\s*(\d+(?:\.\d+)?)\s*(?:–∫–≤\.?\s*–º|–º¬≤)',
        ]

        for pattern in land_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                data['area_land'] = Decimal(match.group(1))
                if self.verbose:
                    self.stdout.write(f"  ‚úÖ –ü–ª–æ—â–∞–¥—å —É—á–∞—Å—Ç–∫–∞: {data['area_land']} –º¬≤")
                break

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–¥–æ–±—Å—Ç–≤–∞
        amenities_text = text
        data['pool'] = any(word in amenities_text for word in ['–±–∞—Å—Å–µ–π–Ω', 'pool', 'swimming'])
        data['parking'] = any(word in amenities_text for word in ['–ø–∞—Ä–∫–æ–≤–∫–∞', 'parking', 'garage'])
        data['security'] = any(word in amenities_text for word in ['–æ—Ö—Ä–∞–Ω–∞', 'security', 'guard'])
        data['gym'] = any(word in amenities_text for word in ['—Å–ø–æ—Ä—Ç–∑–∞–ª', 'gym', 'fitness'])
        data['furnished'] = any(word in amenities_text for word in ['–º–µ–±–µ–ª—å', 'furnished', '–º–µ–±–ª–∏—Ä–æ–≤–∞–Ω–Ω'])

    def extract_property_features(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É–¥–æ–±—Å—Ç–≤ –æ–±—ä–µ–∫—Ç–∞ –∏–∑ –±–ª–æ–∫–æ–≤ —Å –∏–∫–æ–Ω–∫–∞–º–∏"""
        features = []

        # –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ò—â–µ–º —É–¥–æ–±—Å—Ç–≤–∞ –≤ <span class="amenity-entry">English==–†—É—Å—Å–∫–∏–π==Thai==Chinese</span>
        amenity_entries = soup.find_all('span', {'class': 'amenity-entry'})
        if amenity_entries:
            if self.verbose:
                self.stdout.write(f"  –ù–∞–π–¥–µ–Ω–æ amenity-entry —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(amenity_entries)}")

            for entry in amenity_entries:
                entry_text = entry.get_text().strip()
                # –§–æ—Ä–º–∞—Ç: "Air Conditioning==–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä==‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏®==Á©∫Ë∞É"
                # –ë–µ—Ä–µ–º —Ä—É—Å—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç (–≤—Ç–æ—Ä–æ–π –ø–æ—Å–ª–µ ==)
                parts = entry_text.split('==')
                if len(parts) >= 2:
                    feature_name_ru = parts[1].strip()
                    if feature_name_ru and feature_name_ru not in features:
                        features.append(feature_name_ru)
                        if self.verbose:
                            self.stdout.write(f"    ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑ amenity-entry: {feature_name_ru}")
                elif parts:  # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è ==, –±–µ—Ä–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    feature_name = parts[0].strip()
                    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    feature_mapping_simple = {
                        'air conditioning': '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä',
                        'wifi': 'WiFi',
                        'pool': '–ë–∞—Å—Å–µ–π–Ω',
                        'kitchen': '–ö—É—Ö–Ω—è',
                        'free parking': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
                        'shower': '–î—É—à',
                        'bathtub': '–í–∞–Ω–Ω–∞',
                        'fenced area': '–û–≥–æ—Ä–æ–∂–µ–Ω–Ω–∞—è —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è',
                        'video surveillance': '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ',
                        'security': '–û—Ö—Ä–∞–Ω–∞',
                    }
                    feature_name_ru = feature_mapping_simple.get(feature_name.lower(), feature_name)
                    if feature_name_ru not in features:
                        features.append(feature_name_ru)
                        if self.verbose:
                            self.stdout.write(f"    ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ): {feature_name_ru}")

        # –ï—Å–ª–∏ —É–∂–µ –Ω–∞—à–ª–∏ —É–¥–æ–±—Å—Ç–≤–∞ –≤ amenity-entry, –Ω–µ –∏—â–µ–º –¥–∞–ª—å—à–µ
        if features and self.verbose:
            self.stdout.write(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(features)} —É–¥–æ–±—Å—Ç–≤ –≤ amenity-entry, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ –∏–∫–æ–Ω–∫–∞–º")
            return features

        # –ü–†–ò–û–†–ò–¢–ï–¢ 2: –ò—â–µ–º –ø–æ –∏–∫–æ–Ω–∫–∞–º (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ amenity-entry)
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ alt-—Ç–µ–∫—Å—Ç–æ–≤ –∏–∫–æ–Ω–æ–∫ –∫ –Ω–∞–∑–≤–∞–Ω–∏—è–º —É–¥–æ–±—Å—Ç–≤
        feature_mapping = {
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            'air conditioning': '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä',
            'wifi': 'WiFi',
            'pool': '–ë–∞—Å—Å–µ–π–Ω',
            'swimming pool': '–ë–∞—Å—Å–µ–π–Ω',
            'kitchen': '–ö—É—Ö–Ω—è',
            'workplace': '–†–∞–±–æ—á–µ–µ –º–µ—Å—Ç–æ',
            'gym': '–°–ø–æ—Ä—Ç–∑–∞–ª',
            'free parking': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
            'parking': '–ü–∞—Ä–∫–æ–≤–∫–∞',
            'shower': '–î—É—à',
            'elevator': '–õ–∏—Ñ—Ç',
            'video surveillance': '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ',
            'security': '–û—Ö—Ä–∞–Ω–∞',
            'bath': '–í–∞–Ω–Ω–∞',
            'bathtub': '–í–∞–Ω–Ω–∞',
            # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            '–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä': '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä',
            '–±–∞—Å—Å–µ–π–Ω': '–ë–∞—Å—Å–µ–π–Ω',
            '–∫—É—Ö–Ω—è': '–ö—É—Ö–Ω—è',
            '–ø–∞—Ä–∫–æ–≤–∫–∞': '–ü–∞—Ä–∫–æ–≤–∫–∞',
            '–¥—É—à': '–î—É—à',
            '–ª–∏—Ñ—Ç': '–õ–∏—Ñ—Ç',
            '–≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ': '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ',
            '–æ—Ö—Ä–∞–Ω–∞': '–û—Ö—Ä–∞–Ω–∞',
            '–≤–∞–Ω–Ω–∞': '–í–∞–Ω–Ω–∞',
            '—Å–ø–æ—Ä—Ç–∑–∞–ª': '–°–ø–æ—Ä—Ç–∑–∞–ª',
        }

        # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –∏–∫–æ–Ω–∫–∞–º–∏ —É–¥–æ–±—Å—Ç–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫
        amenity_selectors = [
            '.amenities img',           # –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —É–¥–æ–±—Å—Ç–≤
            '.amenities-icons img',     # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
            '.property-amenities img',  # –í–æ–∑–º–æ–∂–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
            '.features img',            # –ë–ª–æ–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            '.property-features img',   # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
            'img[src*="icon-"]',        # –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å "icon-" –≤ –ø—É—Ç–∏
            'img[src*="/icons/"]',      # –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏ icons
            'img[src*="yootheme"]',     # YooTheme –∏–∫–æ–Ω–∫–∏
            'img[src*="UE/ICONS"]',     # UE –∏–∫–æ–Ω–∫–∏
        ]

        for selector in amenity_selectors:
            amenity_images = soup.select(selector)
            if self.verbose:
                self.stdout.write(f"    –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}': –Ω–∞–π–¥–µ–Ω–æ {len(amenity_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

            for img in amenity_images:
                alt_text = img.get('alt', '').lower().strip()
                src = img.get('src', '')

                if self.verbose:
                    self.stdout.write(f"      img: alt='{alt_text}', src='{src}'")

                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ alt-–∞—Ç—Ä–∏–±—É—Ç—É
                feature_name = None
                if alt_text in feature_mapping:
                    feature_name = feature_mapping[alt_text]
                else:
                    # –ï—Å–ª–∏ alt –ø—É—Å—Ç–æ–π, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –≤ src
                    src_filename = src.lower()
                    src_mapping = {
                        'icon-air-conditioning': '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä',
                        'icon-wifi': 'WiFi',
                        'icon-pool': '–ë–∞—Å—Å–µ–π–Ω',
                        'icon-kitchen': '–ö—É—Ö–Ω—è',
                        'icon-workplace': '–†–∞–±–æ—á–µ–µ –º–µ—Å—Ç–æ',
                        'icon-gym': '–°–ø–æ—Ä—Ç–∑–∞–ª',
                        'icon-free-parking': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
                        'icon-shower': '–î—É—à',
                        'elevator': '–õ–∏—Ñ—Ç',
                        'cctv': '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ',
                        'security-worker': '–û—Ö—Ä–∞–Ω–∞',
                    }

                    for file_key, feature_value in src_mapping.items():
                        if file_key in src_filename:
                            feature_name = feature_value
                            break

                if feature_name and feature_name not in features:
                    features.append(feature_name)
                    if self.verbose:
                        self.stdout.write(f"        ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ: {feature_name}")
                elif not feature_name and 'icon-' in src and '/icons/' not in src.lower():
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —É–¥–æ–±—Å—Ç–≤–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∫–æ–Ω–∫–∏
                    # –ü—Ä–∏–º–µ—Ä: icon-double-bed.svg -> icon-double-bed
                    filename = os.path.basename(src).lower()
                    if filename.startswith('icon-'):
                        icon_name = filename.replace('icon-', '').replace('.svg', '').replace('.png', '')
                        # –ò—Å–∫–ª—é—á–∞–µ–º –∏–∫–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —É–¥–æ–±—Å—Ç–≤–∞–º–∏
                        exclude_icons = ['double-bed', 'bathtub', 'single-bed', 'sofa-bed']

                        if icon_name not in exclude_icons:
                            if self.verbose:
                                self.stdout.write(f"        ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –∏–∫–æ–Ω–∫–∞: {icon_name} (src: {src})")
                                self.stdout.write(f"        üí° –î–æ–±–∞–≤—å—Ç–µ –≤ src_mapping: '{icon_name}': '–ù–∞–∑–≤–∞–Ω–∏–µ —É–¥–æ–±—Å—Ç–≤–∞'")
                        elif self.verbose:
                            # –ù–µ –≤—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫—É –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                            pass
                    elif self.verbose and (alt_text or '/icons/' in src.lower()):
                        self.stdout.write(f"        ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è: alt='{alt_text}', src='{src}'")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –¥–ª—è —É–¥–æ–±—Å—Ç–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ –≤ –∏–∫–æ–Ω–∫–∞—Ö
        text_content = soup.get_text().lower()
        text_features = {
            '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä': ['–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä', 'air conditioning', 'aircon'],
            'WiFi': ['wifi', 'wi-fi', '–≤–∞–π-—Ñ–∞–π', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç'],
            '–ë–∞—Å—Å–µ–π–Ω': ['–±–∞—Å—Å–µ–π–Ω', 'pool', 'swimming pool'],
            '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞': ['–ø–∞—Ä–∫–æ–≤–∫–∞', 'parking', 'garage', '–≥–∞—Ä–∞–∂'],
            '–û—Ö—Ä–∞–Ω–∞': ['–æ—Ö—Ä–∞–Ω–∞', 'security', 'guard', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'],
            '–°–ø–æ—Ä—Ç–∑–∞–ª': ['—Å–ø–æ—Ä—Ç–∑–∞–ª', 'gym', 'fitness', '—Ñ–∏—Ç–Ω–µ—Å'],
            '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ': ['–≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ', 'cctv', 'surveillance', '–∫–∞–º–µ—Ä—ã'],
        }

        for feature_name, keywords in text_features.items():
            if feature_name not in features and any(keyword in text_content for keyword in keywords):
                features.append(feature_name)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —É–¥–æ–±—Å—Ç–≤ –∫ –µ–¥–∏–Ω–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
        normalized_features = []
        feature_normalize_map = {
            '–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä': '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä',
            '–ø–∞—Ä–∫–æ–≤–∫–∞': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
            'parking': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
            'free parking': '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞',
            '—Å–ø–æ—Ä—Ç–∑–∞–ª': '–°–ø–æ—Ä—Ç–∑–∞–ª',
            'gym': '–°–ø–æ—Ä—Ç–∑–∞–ª',
        }

        for feature in features:
            normalized = feature_normalize_map.get(feature.lower(), feature)
            if normalized not in normalized_features:
                normalized_features.append(normalized)

        features = normalized_features

        if self.verbose:
            self.stdout.write(f"  –ù–∞–π–¥–µ–Ω–Ω—ã–µ —É–¥–æ–±—Å—Ç–≤–∞: {', '.join(features) if features else '–Ω–µ—Ç'}")

        return features

    def extract_property_price(self, soup, data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –æ–±—ä–µ–∫—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π THB"""
        text = soup.get_text()

        if self.verbose:
            self.stdout.write(f"  –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "—Ü–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É" –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑
        price_on_request_patterns = [
            '—Ü–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É', 'price on request', '–ø–æ –∑–∞–ø—Ä–æ—Å—É', 'price upon request',
            'contact for price', '—É–∑–Ω–∞–≤–∞–π—Ç–µ —Ü–µ–Ω—É', 'price: request', '—Ü–µ–Ω–∞: –∑–∞–ø—Ä–æ—Å',
            '–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ —Ü–µ–Ω–æ–π', 'ask for price'
        ]

        text_lower = text.lower()
        for pattern in price_on_request_patterns:
            if pattern in text_lower:
                if self.verbose:
                    self.stdout.write(f"    –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ '{pattern}' - —Ü–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–∫—Ç –±–µ–∑ —Ü–µ–Ω—ã")
                data['deal_type'] = 'sale'
                # –ù–µ –∑–∞–ø–æ–ª–Ω—è–µ–º –ø–æ–ª—è —Ü–µ–Ω—ã, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–±—ä–µ–∫—Ç–∞
                return

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–Ω—É –æ–±—ä–µ–∫—Ç–∞ - —Ç–æ—á–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –∏–º–µ–µ—Ç –≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        main_price_elements = soup.select('.uk-text-lead.price, .uk-text-lead, .property-price, .price-main, h1, h2')
        specific_price_blocks = []

        for element in main_price_elements:
            element_text = element.get_text().strip()
            if element_text and any(char.isdigit() for char in element_text):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç - –∏—Å–∫–ª—é—á–∞–µ–º –±–ª–æ–∫–∏ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                element_context = str(element.parent.parent if element.parent and element.parent.parent else element.parent if element.parent else element)

                # –ò—Å–∫–ª—é—á–∞–µ–º –±–ª–æ–∫–∏ —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
                exclude_indicators = [
                    'similar', 'related', 'other', 'recommendation', '–ø–æ—Ö–æ–∂–∏–µ', '–¥—Ä—É–≥–∏–µ',
                    'property-card', 'property-item', 'listing-item', '–æ–±—ä–µ–∫—Ç—ã'
                ]

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –±–ª–æ–∫ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
                is_excluded = any(indicator in element_context.lower() for indicator in exclude_indicators)

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é - –æ—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞ –æ–±—ã—á–Ω–æ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                element_position = len(soup.get_text()[:soup.get_text().find(element_text)])
                page_length = len(soup.get_text())
                is_in_top_part = element_position < page_length * 0.3  # –ü–µ—Ä–≤—ã–µ 30% —Å—Ç—Ä–∞–Ω–∏—Ü—ã

                if not is_excluded and is_in_top_part:
                    specific_price_blocks.append(element_text)
                    if self.verbose:
                        self.stdout.write(f"    –ù–∞–π–¥–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Ü–µ–Ω—ã: '{element_text}' (–ø–æ–∑–∏—Ü–∏—è: {element_position}, –∏—Å–∫–ª—é—á–µ–Ω: {is_excluded})")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ —Ü–µ–Ω—ã
        price_elements = soup.select('.price, [class*="price"]')
        general_price_blocks = []

        for element in price_elements:
            element_text = element.get_text().strip()
            if element_text and any(char.isdigit() for char in element_text):
                general_price_blocks.append(element_text)
                if self.verbose:
                    self.stdout.write(f"    –ù–∞–π–¥–µ–Ω –±–ª–æ–∫ —Ü–µ–Ω—ã: '{element_text}'")

        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –ø–æ–∏—Å–∫: —Å–Ω–∞—á–∞–ª–∞ –æ—Å–Ω–æ–≤–Ω—ã–µ –±–ª–æ–∫–∏, –ø–æ—Ç–æ–º –æ–±—â–∏–µ, –∑–∞—Ç–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        price_text_blocks = specific_price_blocks + general_price_blocks
        if not price_text_blocks:
            price_text_blocks = [text]

        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ THB —Ü–µ–Ω
        price_patterns = [
            # THB —Å —Å–∏–º–≤–æ–ª–æ–º ‡∏ø (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            (r'‡∏ø\s*(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)', 'THB', 100),
            (r'(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)\s*‡∏ø', 'THB', 100),

            # THB —Ç–µ–∫—Å—Ç–æ–º (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            (r'(\d{1,3}(?:[,\s]\d{3})*)\s*(?:baht|–±–∞—Ç)', 'THB', 90),

            # USD —Å —Å–∏–º–≤–æ–ª–æ–º $ (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            (r'\$\s*(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)', 'USD', 70),
            (r'(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)\s*\$', 'USD', 70),

            # RUB —Å —Å–∏–º–≤–æ–ª–æ–º ‚ÇΩ (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            (r'‚ÇΩ\s*(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)', 'RUB', 60),
            (r'(\d{1,3}(?:[,\s]\d{3})*(?:\.\d{2})?)\s*‚ÇΩ', 'RUB', 60),

            # –ú–∏–ª–ª–∏–æ–Ω—ã THB (—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
            (r'(\d{1,3}(?:\.\d{1,2})?)\s*(?:million|–º–ª–Ω|mil)?\s*(?:baht|‡∏ø|–±–∞—Ç)', 'THB_MILLION', 95),

            # –ë–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞ –±–µ–∑ —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç)
            (r'(\d{1,3}(?:[,\s]\d{3}){2,})', 'UNKNOWN', 30),  # 7+ —Ü–∏—Ñ—Ä —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
            (r'(\d{7,})', 'UNKNOWN', 20),  # –ü—Ä–æ—Å—Ç–æ –±–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞
        ]

        found_prices = []

        for text_block in price_text_blocks:
            for pattern, currency, priority in price_patterns:
                matches = re.findall(pattern, text_block, re.IGNORECASE)
                for match in matches:
                    # –û—á–∏—â–∞–µ–º —Ü–µ–Ω—É –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –∑–∞–ø—è—Ç—ã—Ö
                    price_str = str(match).replace(' ', '').replace(',', '').replace('.', '')
                    try:
                        price = int(price_str)

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∏–ª–ª–∏–æ–Ω–æ–≤
                        if currency == 'THB_MILLION':
                            price = price * 1000000
                            currency = 'THB'

                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–∞–∑—É–º–Ω—ã–µ —Ü–µ–Ω—ã
                        if currency == 'THB' and 50000 <= price <= 100000000:  # THB: 50k - 100M
                            found_prices.append((price, currency, priority))
                        elif currency == 'USD' and 10000 <= price <= 5000000:  # USD: 10k - 5M
                            found_prices.append((price, currency, priority))
                        elif currency == 'RUB' and 500000 <= price <= 500000000:  # RUB: 500k - 500M
                            found_prices.append((price, currency, priority))
                        elif currency == 'UNKNOWN' and 100000 <= price <= 100000000:  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≤–∞–ª—é—Ç–∞
                            found_prices.append((price, currency, priority))

                        if self.verbose:
                            self.stdout.write(f"    –ù–∞–π–¥–µ–Ω–∞ —Ü–µ–Ω–∞: {price:,} {currency} (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority})")

                    except ValueError:
                        continue

        if not found_prices:
            if self.verbose:
                self.stdout.write(f"    –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            data['deal_type'] = 'sale'
            return

        # –î–ª—è —Ü–µ–Ω —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º, –≤—ã–±–∏—Ä–∞–µ–º —Ç—É –∫–æ—Ç–æ—Ä–∞—è –±–ª–∏–∂–µ –∫ –∑–∞–≥–æ–ª–æ–≤–∫—É
        if len(found_prices) > 1:
            # –ù–∞–π–¥–µ–º H1 –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –µ–≥–æ –ø–æ–∑–∏—Ü–∏—é
            h1_element = soup.find('h1')
            if h1_element:
                h1_text = h1_element.get_text()
                h1_position = soup.get_text().find(h1_text)

                # –î–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–Ω—ã –Ω–∞–π–¥–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ H1
                price_distances = []
                for price, currency, priority in found_prices:
                    # –ù–∞–π–¥–µ–º –ø–æ–∑–∏—Ü–∏—é —ç—Ç–æ–π —Ü–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ
                    price_str = f"{price:,}".replace(",", " ")  # –§–æ—Ä–º–∞—Ç —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
                    price_position = soup.get_text().find(str(price))
                    if price_position == -1:
                        price_position = soup.get_text().find(price_str)

                    distance = abs(price_position - h1_position) if price_position != -1 else float('inf')
                    price_distances.append((price, currency, priority, distance))

                    if self.verbose:
                        self.stdout.write(f"    –¶–µ–Ω–∞ {price:,} {currency}: –ø–æ–∑–∏—Ü–∏—è {price_position}, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ H1: {distance}")

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É, –ø–æ—Ç–æ–º –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –¥–æ H1 (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
                price_distances.sort(key=lambda x: (-x[2], x[3]))
                best_price, best_currency, _, best_distance = price_distances[0]

                if self.verbose:
                    self.stdout.write(f"    –í—ã–±—Ä–∞–Ω–∞ —Ü–µ–Ω–∞ –±–ª–∏–∂–∞–π—à–∞—è –∫ H1: {best_price:,} {best_currency} (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {best_distance})")
            else:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É, –ø–æ—Ç–æ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ü–µ–Ω—ã
                found_prices.sort(key=lambda x: (-x[2], -x[0]))
                best_price, best_currency, _ = found_prices[0]
        else:
            best_price, best_currency, _ = found_prices[0]

        if self.verbose:
            self.stdout.write(f"    –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ü–µ–Ω—ã: {found_prices}")
            self.stdout.write(f"    –í—ã–±—Ä–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: {best_price:,} {best_currency}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–¥–µ–ª–∫–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç URL)
        url_lower = data.get('original_url', '').lower()
        text_lower = text.lower()

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º URL - –Ω–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if 'for-sale' in url_lower or '/buy/' in url_lower or '/real-estate/buy' in url_lower:
            is_rent = False
            if self.verbose:
                self.stdout.write(f"    –¢–∏–ø —Å–¥–µ–ª–∫–∏ –∏–∑ URL: –ü–†–û–î–ê–ñ–ê")
        elif 'for-rent' in url_lower or '/rent/' in url_lower or '/real-estate/rent' in url_lower or 'rental' in url_lower:
            is_rent = True
            if self.verbose:
                self.stdout.write(f"    –¢–∏–ø —Å–¥–µ–ª–∫–∏ –∏–∑ URL: –ê–†–ï–ù–î–ê")
        else:
            # –ï—Å–ª–∏ –≤ URL —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ /real-estate/villa/123-... - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–¥–∞–∂–µ–π
            # —Ç–∞–∫ –∫–∞–∫ undersunestate.com –∏—Å–ø–æ–ª—å–∑—É–µ—Ç /real-estate/rent –¥–ª—è –∞—Ä–µ–Ω–¥—ã
            if '/real-estate/' in url_lower and '/rent' not in url_lower:
                is_rent = False
                if self.verbose:
                    self.stdout.write(f"    –¢–∏–ø —Å–¥–µ–ª–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ URL): –ü–†–û–î–ê–ñ–ê")
            else:
                # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ URL —Å–æ–≤—Å–µ–º –Ω–µ –ø–æ–º–æ–≥, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
                is_rent = any(word in text_lower for word in [
                    '–∞—Ä–µ–Ω–¥', 'rent', 'rental', 'lease', '/–º–µ—Å', 'monthly',
                    'per month', '–≤ –º–µ—Å—è—Ü', '–∑–∞ –º–µ—Å—è—Ü'
                ])
                if self.verbose:
                    self.stdout.write(f"    –¢–∏–ø —Å–¥–µ–ª–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞: {'–ê–†–ï–ù–î–ê' if is_rent else '–ü–†–û–î–ê–ñ–ê'}")

        # –õ–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
        if is_rent:
            data['deal_type'] = 'rent'

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ THB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ –∫—É—Ä—Å—ã)
            if best_currency == 'USD':
                thb_price = best_price * 35  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å USD -> THB
            elif best_currency == 'RUB':
                thb_price = best_price * 0.5  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å RUB -> THB
            elif best_currency == 'UNKNOWN':
                # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –±–æ–ª—å—à–∞—è, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ –≥–æ–¥–æ–≤–∞—è –∞—Ä–µ–Ω–¥–∞ –≤ THB
                if best_price > 500000:
                    thb_price = best_price // 12  # –î–µ–ª–∏–º –Ω–∞ 12 –º–µ—Å—è—Ü–µ–≤
                else:
                    thb_price = best_price
            else:
                thb_price = best_price

            data['price_rent_monthly_thb'] = Decimal(str(int(thb_price)))

            if self.verbose:
                self.stdout.write(f"    –ê—Ä–µ–Ω–¥–∞: {thb_price:,.0f} THB/–º–µ—Å—è—Ü")
        else:
            data['deal_type'] = 'sale'

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ THB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if best_currency == 'USD':
                thb_price = best_price * 35  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å USD -> THB
            elif best_currency == 'RUB':
                thb_price = best_price * 0.5  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å RUB -> THB
            elif best_currency == 'UNKNOWN':
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ THB
                thb_price = best_price
            else:
                thb_price = best_price

            data['price_sale_thb'] = Decimal(str(int(thb_price)))

            if self.verbose:
                self.stdout.write(f"    –ü—Ä–æ–¥–∞–∂–∞: {thb_price:,.0f} THB")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –µ—Å–ª–∏ –æ–Ω–∞ –≤ –¥—Ä—É–≥–æ–π –≤–∞–ª—é—Ç–µ
        if best_currency == 'USD':
            if is_rent:
                data['price_rent_monthly'] = Decimal(str(best_price))
            else:
                data['price_sale_usd'] = Decimal(str(best_price))
        elif best_currency == 'RUB':
            if is_rent:
                data['price_rent_monthly_rub'] = Decimal(str(best_price))
            else:
                data['price_sale_rub'] = Decimal(str(best_price))

    def extract_property_images(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–±—ä–µ–∫—Ç–∞"""
        images = []
        image_variants = {}  # –•—Ä–∞–Ω–∏–º –≤–∞—Ä–∏–∞–Ω—Ç—ã: {base_name: [{'url': str, 'width': int}]}

        def store_variant(base_name, full_url, width_hint=0, source_desc=None):
            """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≥—Ä—É–ø–ø–∏—Ä—É—è –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏"""
            if base_name:
                variants = image_variants.setdefault(base_name, [])
                if not any(v['url'] == full_url for v in variants):
                    variants.append({'url': full_url, 'width': width_hint or 0})
                    if self.verbose and source_desc:
                        label = f"{full_url} ({width_hint}w)" if width_hint else full_url
                        self.stdout.write(f"    –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑ {source_desc}: {label}")
            else:
                if full_url not in images:
                    images.append(full_url)
                    if self.verbose and source_desc:
                        self.stdout.write(f"    –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑ {source_desc}: {full_url}")

        # –°–Ω–∞—á–∞–ª–∞ –ø–∞—Ä—Å–∏–º <picture><source> —ç–ª–µ–º–µ–Ω—Ç—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –∑–¥–µ—Å—å –æ–±—ã—á–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ!)
        picture_sources = soup.select('picture source[srcset], picture source[data-srcset]')
        if self.verbose:
            self.stdout.write(f"  –ù–∞–π–¥–µ–Ω–æ <picture><source> —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(picture_sources)}")

        for source in picture_sources:
            srcset_values = []

            for attr in ('srcset', 'data-srcset', 'data-src'):
                val = source.get(attr)
                if val:
                    srcset_values.append(val)

            for srcset in srcset_values:
                if not srcset:
                    continue

                # –ü–∞—Ä—Å–∏–º srcset: "image1.webp 768w, image2.webp 1024w, image3.webp 1920w"
                for srcset_item in srcset.split(','):
                    srcset_item = srcset_item.strip()
                    if not srcset_item:
                        continue

                    parts = srcset_item.split()
                    if not parts:
                        continue

                    src = parts[0]
                    width_hint = 0
                    for part in parts[1:]:
                        if part.endswith('w') and part[:-1].isdigit():
                            width_hint = int(part[:-1])
                            break

                    if src and self.is_valid_property_image(src):
                        full_url = urljoin(self.base_url, src)
                        base_name = self.get_image_base_name(src)
                        store_variant(base_name, full_url, width_hint, source_desc='<source>')

        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
        image_selectors = [
            # –û—Å–Ω–æ–≤–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
            'img[src*="/images/"]',
            'img[data-src*="/images/"]',

            # –ì–∞–ª–µ—Ä–µ–∏ –∏ —Å–ª–∞–π–¥–µ—Ä—ã
            '.gallery img',
            '.slider img',
            '.property-gallery img',
            '.swiper img',
            '.carousel img',

            # YooTheme –∏ Joomla —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            'img[src*="yootheme"]',
            'img[src*="templates"]',
            'img[src*="cache"]',

            # –û–±—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
            'main img',
            'article img',
            '.content img',

            # Lazy loading –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            'img[data-lazy]',
            'img[loading="lazy"]',

            # –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –±–æ–ª—å—à–∏–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ –≤ URL
            'img[src*="800"]',
            'img[src*="1200"]',
            'img[src*="1920"]',

            # –û–±—â–∏–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            'img'
        ]

        for selector in image_selectors:
            img_elements = soup.select(selector)
            for img in img_elements:
                sources = []

                if img.get('src'):
                    sources.append((img.get('src'), 0, '<img src>'))
                if img.get('data-src'):
                    sources.append((img.get('data-src'), 0, '<img data-src>'))
                if img.get('data-lazy'):
                    sources.append((img.get('data-lazy'), 0, '<img data-lazy>'))
                if img.get('data-original'):
                    sources.append((img.get('data-original'), 0, '<img data-original>'))

                for attr, label in (('srcset', '<img srcset>'), ('data-srcset', '<img data-srcset>')):
                    srcset = img.get(attr)
                    if srcset:
                        for srcset_item in srcset.split(','):
                            srcset_item = srcset_item.strip()
                            if not srcset_item:
                                continue
                            url_parts = srcset_item.split()
                            if not url_parts:
                                continue
                            url_value = url_parts[0]
                            width_hint = 0
                            for part in url_parts[1:]:
                                if part.endswith('w') and part[:-1].isdigit():
                                    width_hint = int(part[:-1])
                                    break
                            sources.append((url_value, width_hint, label))

                for src, width_hint, label in sources:
                    if src and self.is_valid_property_image(src):
                        full_url = urljoin(self.base_url, src)
                        base_name = self.get_image_base_name(src)
                        store_variant(base_name, full_url, width_hint, source_desc=label)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ data-src –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –±–µ–∑ <img>
        background_selectors = [
            '[data-src]',
            '[data-image]',
            '[data-img]',
            '[data-background]',
            '[style*="background-image"]'
        ]

        for selector in background_selectors:
            elements = soup.select(selector)
            for el in elements:
                potential_sources = []

                # data-* –∞—Ç—Ä–∏–±—É—Ç—ã —á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä—è–º–æ–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                for attr in ['data-src', 'data-image', 'data-img', 'data-background']:
                    val = el.get(attr)
                    if val:
                        potential_sources.append(val)

                # –ó–Ω–∞—á–µ–Ω–∏—è background-image –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ url()
                style = el.get('style', '')
                if 'background-image' in style:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è url("...") –∏–ª–∏ url('...')
                    fragments = style.split('url(')
                    for fragment in fragments[1:]:
                        url_part = fragment.split(')', 1)[0].strip().strip("\"'")
                        if url_part:
                            potential_sources.append(url_part)

                for src in potential_sources:
                    if not src:
                        continue
                    if self.is_valid_property_image(src):
                        full_url = urljoin(self.base_url, src)
                        base_name = self.get_image_base_name(src)
                        store_variant(base_name, full_url, 0, source_desc='background/data-src')

        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for base_name, variants in image_variants.items():
            best_image = self.select_best_image_quality(variants)
            if best_image and best_image not in images:
                images.append(best_image)
                if self.verbose and len(variants) > 1:
                    variant_descriptions = [
                        f"{variant['url']} ({variant['width']}w)" if variant.get('width') else variant['url']
                        for variant in variants
                    ]
                    self.stdout.write(f"  –í—ã–±—Ä–∞–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è {base_name}: {best_image}")
                    self.stdout.write(f"    –ò–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {variant_descriptions}")

        return images

    def get_image_base_name(self, src):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ –∫—ç—à-—Ö–µ—à–∞ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è"""
        # –ü—Ä–∏–º–µ—Ä: /templates/yootheme/cache/d2/40_LIVING1-d201ddf5.webp -> 40_LIVING1
        # –ü—Ä–∏–º–µ—Ä: /templates/yootheme/cache/d8/40_LIVING1-d87d1c3c.jpeg -> 40_LIVING1

        filename = os.path.basename(src)

        # –£–¥–∞–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        name_without_ext = os.path.splitext(filename)[0]

        # –£–¥–∞–ª—è–µ–º –∫—ç—à-—Ö–µ—à (–æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–µ—Ñ–∏—Å–∞)
        # 40_LIVING1-d201ddf5 -> 40_LIVING1
        if '-' in name_without_ext:
            base_name = name_without_ext.rsplit('-', 1)[0]
            return base_name

        return name_without_ext

    def select_best_image_quality(self, image_variants):
        """–í—ã–±–∏—Ä–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
        if not image_variants:
            return None

        if len(image_variants) == 1:
            return image_variants[0]['url']

        format_priority = {'.webp': 3, '.png': 2, '.jpg': 1, '.jpeg': 1}

        scored_images = []
        for variant in image_variants:
            url = variant['url']
            width_hint = variant.get('width') or 0
            score = width_hint
            url_lower = url.lower()

            for ext, priority in format_priority.items():
                if ext in url_lower:
                    score += priority * 10000
                    break

            if not width_hint:
                for size, bump in [(1920, 60), (1600, 55), (1440, 50), (1366, 45), (1200, 40), (1024, 35), (960, 30), (800, 25), (768, 20), (600, 10)]:
                    if str(size) in url_lower:
                        score += bump
                        break

            scored_images.append((score, width_hint, url))

        scored_images.sort(key=lambda x: (x[0], x[1], x[2]), reverse=True)

        if self.verbose and len(scored_images) > 1:
            self.stdout.write("    –û—Ü–µ–Ω–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
            for score, width_hint, url in scored_images:
                width_note = f" ({width_hint}w)" if width_hint else ""
                self.stdout.write(f"      {score}: {url}{width_note}")

        return scored_images[0][2]

    def extract_property_type_and_location(self, soup, url, data):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏ –ª–æ–∫–∞—Ü–∏–∏"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ URL
        url_parts = url.split('/')

        # –¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ URL –∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω (–æ—Ç –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ –∫ –æ–±—â–µ–º—É)
        type_mapping = [
            ('apartment', 'condo'),
            ('condominium', 'condo'),
            ('condo', 'condo'),
            ('townhouses-for-sale', 'townhouse'),
            ('townhouses-for-rent', 'townhouse'),
            ('townhouse-for-sale', 'townhouse'),
            ('townhouse-for-rent', 'townhouse'),
            ('townhouses', 'townhouse'),
            ('town-house', 'townhouse'),
            ('townhouse', 'townhouse'),
            ('villa', 'villa'),
            ('house', 'villa'),
            ('land-plot', 'land'),  # –ë–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ —Å–Ω–∞—á–∞–ª–∞
            ('land', 'land'),
        ]

        # –ò—â–µ–º –≤ URL - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º —Ç–µ—Ä–º–∏–Ω–∞–º
        for url_type, db_type in type_mapping:
            if url_type in url.lower():
                data['property_type'] = db_type
                if self.verbose:
                    self.stdout.write(f"  –¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ URL: '{url_type}' -> {db_type}")
                break

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ URL, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        if 'property_type' not in data:
            text = soup.get_text().lower()
            for text_type, db_type in type_mapping:
                if text_type in text:
                    data['property_type'] = db_type
                    if self.verbose:
                        self.stdout.write(f"  –¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞: '{text_type}' -> {db_type}")
                    break

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –≤–∏–ª–ª–∞
        if 'property_type' not in data:
            data['property_type'] = 'villa'

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–π–æ–Ω –∏–∑ URL - –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:
        # https://undersunestate.com/ru/real-estate/thalang/cherng-talay/450-1-bedroom-apartment
        # url_parts = ['https:', '', 'undersunestate.com', 'ru', 'real-estate', 'thalang', 'cherng-talay', '450-...']
        if len(url_parts) >= 8 and 'real-estate' in url_parts:
            real_estate_index = url_parts.index('real-estate')
            if real_estate_index + 2 < len(url_parts):
                district_slug = url_parts[real_estate_index + 1]  # thalang
                location_slug = url_parts[real_estate_index + 2]  # cherng-talay

                data['district_slug'] = district_slug
                data['location_slug'] = location_slug

    def extract_property_coordinates(self, soup, data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –æ–±—ä–µ–∫—Ç–∞ –∏–∑ —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Maps"""
        if self.verbose:
            self.stdout.write(f"  –ü–æ–∏—Å–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç...")

        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Maps —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
        map_selectors = [
            'a[href*="google.com/maps"]',
            'a[href*="maps.google.com"]',
            'a[href*="goo.gl/maps"]',
            '.map-link',
            '.location-link'
        ]

        coordinates_found = False

        for selector in map_selectors:
            map_links = soup.select(selector)

            for link in map_links:
                href = link.get('href', '')
                if not href:
                    continue

                if self.verbose:
                    self.stdout.write(f"    –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫—É: {href}")

                # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ Google Maps —Å—Å—ã–ª–æ–∫
                coordinate_patterns = [
                    # –§–æ—Ä–º–∞—Ç: http://www.google.com/maps/place/8.020924818147838,98.3133195880343
                    r'/place/(-?\d+\.\d+),(-?\d+\.\d+)',
                    # –§–æ—Ä–º–∞—Ç: https://maps.google.com/maps?q=8.020924818147838,98.3133195880343
                    r'[?&]q=(-?\d+\.\d+),(-?\d+\.\d+)',
                    # –§–æ—Ä–º–∞—Ç: https://www.google.com/maps/@8.020924818147838,98.3133195880343,17z
                    r'/@(-?\d+\.\d+),(-?\d+\.\d+)',
                    # –§–æ—Ä–º–∞—Ç: https://maps.google.com/?ll=8.020924818147838,98.3133195880343
                    r'[?&]ll=(-?\d+\.\d+),(-?\d+\.\d+)',
                    # –û–±—â–∏–π —Ñ–æ—Ä–º–∞—Ç: –ª—é–±—ã–µ –¥–≤–∞ —á–∏—Å–ª–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
                    r'(-?\d+\.\d{6,}),(-?\d+\.\d{6,})'
                ]

                for pattern in coordinate_patterns:
                    match = re.search(pattern, href)
                    if match:
                        try:
                            latitude = float(match.group(1))
                            longitude = float(match.group(2))

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–ø—Ä–∏–º–µ—Ä–Ω–æ –¥–ª—è –¢–∞–∏–ª–∞–Ω–¥–∞/–Æ–≥–æ-–í–æ—Å—Ç–æ—á–Ω–æ–π –ê–∑–∏–∏)
                            if 5.0 <= latitude <= 20.0 and 95.0 <= longitude <= 105.0:
                                data['latitude'] = Decimal(str(latitude))
                                data['longitude'] = Decimal(str(longitude))
                                coordinates_found = True

                                if self.verbose:
                                    self.stdout.write(f"    ‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {latitude}, {longitude}")

                                break
                            else:
                                if self.verbose:
                                    self.stdout.write(f"    ‚ùå –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞: {latitude}, {longitude}")

                        except (ValueError, TypeError):
                            continue

                if coordinates_found:
                    break

            if coordinates_found:
                break

        if not coordinates_found:
            if self.verbose:
                self.stdout.write(f"    ‚ùå –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    def is_valid_property_image(self, src):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        if not src:
            return False

        src_lower = src.lower()

        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        exclude_patterns = [
            '.svg', 'icon-', 'logo', 'avatar', 'social',
            'phone', 'email',
            'button', 'btn-', 'arrow', 'flag-', 'flags/',
        ]

        for pattern in exclude_patterns:
            if pattern in src_lower:
                return False

        # –í–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã
        include_patterns = ['.jpg', '.jpeg', '.png', '.webp']
        return any(pattern in src_lower for pattern in include_patterns)

    def generate_slug(self, url, title):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è slug –∏–∑ URL –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å slug –∏–∑ URL (–ø–æ—Å–ª–µ ID)
        url_match = re.search(r'/(\d+)-(.+?)(?:/|$)', url)
        if url_match:
            url_slug = url_match.group(2)
            cleaned_slug = slugify(url_slug)
            if cleaned_slug and len(cleaned_slug) > 3:
                return cleaned_slug[:200]

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        title_slug = slugify(title)
        if title_slug:
            return title_slug[:200]

        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º ID
        original_id_match = re.search(r'/(\d+)-', url)
        if original_id_match:
            return f"property-{original_id_match.group(1)}"

        return "no-slug"

    def get_or_create_property_type(self, property_type_name):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        type_mapping = {
            'villa': ('villa', '–í–∏–ª–ª–∞'),
            'condo': ('condo', '–ö–æ–Ω–¥–æ–º–∏–Ω–∏—É–º'),
            'townhouse': ('townhouse', '–¢–∞—É–Ω—Ö–∞—É—Å'),
            'land': ('land', '–ó–µ–º–µ–ª—å–Ω—ã–π —É—á–∞—Å—Ç–æ–∫'),
            'investment': ('investment', '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'),
            'business': ('business', '–ì–æ—Ç–æ–≤—ã–π –±–∏–∑–Ω–µ—Å')
        }

        type_name, display_name = type_mapping.get(property_type_name, ('villa', '–í–∏–ª–ª–∞'))

        property_type, created = PropertyType.objects.get_or_create(
            name=type_name,
            defaults={'name_display': display_name}
        )

        if created and self.verbose:
            self.stdout.write(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: {display_name}")

        return property_type

    def get_or_create_district(self, district_slug, location_slug=None):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —Ä–∞–π–æ–Ω –∏ –ª–æ–∫–∞—Ü–∏—é"""
        # –ö–∞—Ä—Ç–∞ —Ä–∞–π–æ–Ω–æ–≤
        district_mapping = {
            'thalang': 'Thalang',
            'kathu': 'Kathu',
            'muang-phuket': 'Muang Phuket',
            'phuket': 'Phuket'
        }

        district_name = district_mapping.get(district_slug, district_slug.replace('-', ' ').title())

        district, created = District.objects.get_or_create(
            slug=district_slug,
            defaults={'name': district_name}
        )

        if created and self.verbose:
            self.stdout.write(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ä–∞–π–æ–Ω: {district_name}")

        location = None
        if location_slug and location_slug != district_slug:
            location_name = location_slug.replace('-', ' ').title()
            location, created = Location.objects.get_or_create(
                slug=location_slug,
                district=district,
                defaults={'name': location_name}
            )

            if created and self.verbose:
                self.stdout.write(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –ª–æ–∫–∞—Ü–∏—è: {location_name}")

        return district, location

    def find_duplicate_property(self, data):
        """–ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –ò—â–µ–º –ø–æ slug (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL –æ–±—ä–µ–∫—Ç–∞)
        if data.get('slug'):
            existing = Property.objects.filter(slug=data['slug']).first()
            if existing:
                if self.verbose:
                    self.stdout.write(f"  üîç –î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω –ø–æ slug='{data['slug']}'")
                return existing

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ò—â–µ–º –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞ + —Ü–µ–Ω—ã (–∑–∞—â–∏—Ç–∞ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏)
        if data.get('title'):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ü–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏
            if data.get('price_sale_thb'):
                existing = Property.objects.filter(
                    title=data['title'],
                    price_sale_thb=data['price_sale_thb']
                ).first()
                if existing:
                    if self.verbose:
                        self.stdout.write(f"  üîç –î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω –ø–æ title + price_sale_thb")
                    return existing

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ü–µ–Ω–∞ –∞—Ä–µ–Ω–¥—ã
            if data.get('price_rent_monthly_thb'):
                existing = Property.objects.filter(
                    title=data['title'],
                    price_rent_monthly_thb=data['price_rent_monthly_thb']
                ).first()
                if existing:
                    if self.verbose:
                        self.stdout.write(f"  üîç –î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω –ø–æ title + price_rent_monthly_thb")
                    return existing

            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –¢–æ–ª—å–∫–æ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É (—Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º - –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–æ–∂–Ω–æ–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ)
            existing = Property.objects.filter(title=data['title']).first()
            if existing:
                if self.verbose:
                    self.stdout.write(f"  ‚ö†Ô∏è  –î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω –¢–û–õ–¨–ö–û –ø–æ title (–≤–æ–∑–º–æ–∂–Ω–æ –ª–æ–∂–Ω–æ–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ)")
                return existing

        return None

    def save_property(self, data):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        # –£–±–∏—Ä–∞–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏
        clean_data = {k: v for k, v in data.items() if k not in ['images', 'original_url', 'property_type', 'district_slug', 'location_slug', 'features']}

        # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        duplicate = self.find_duplicate_property(data)
        if duplicate:
            self._is_duplicate = True
            if self.verbose:
                self.stdout.write(self.style.WARNING(f"–ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {duplicate.title}"))

            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç–∞
            updated = False
            for key, value in clean_data.items():
                if value and (not getattr(duplicate, key, None) or key in ['description']):
                    setattr(duplicate, key, value)
                    updated = True

            if updated:
                duplicate.save()
                if self.verbose:
                    self.stdout.write(self.style.SUCCESS(f"–û–±–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞"))

            return duplicate

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç
        self._is_duplicate = False

        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
        property_type = self.get_or_create_property_type(data.get('property_type', 'villa'))
        clean_data['property_type'] = property_type

        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —Ä–∞–π–æ–Ω –∏ –ª–æ–∫–∞—Ü–∏—é
        district, location = self.get_or_create_district(
            data.get('district_slug', 'phuket'),
            data.get('location_slug')
        )
        clean_data['district'] = district
        if location:
            clean_data['location'] = location

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        clean_data['status'] = 'available'
        clean_data['is_active'] = True

        property_obj = Property.objects.create(**clean_data)

        if self.verbose:
            self.stdout.write(self.style.SUCCESS(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç: {property_obj.title}"))

        return property_obj

    def save_property_features(self, property_obj, feature_names):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –æ–±—ä–µ–∫—Ç–∞ —Å —É–¥–æ–±—Å—Ç–≤–∞–º–∏"""
        from apps.properties.models import PropertyFeature, PropertyFeatureRelation

        if not feature_names:
            return

        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–≤—è–∑–∏ –¥–ª—è —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        PropertyFeatureRelation.objects.filter(property=property_obj).delete()

        for feature_name in feature_names:
            # –ò—â–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —É–¥–æ–±—Å—Ç–≤–æ
            feature, created = PropertyFeature.objects.get_or_create(
                name=feature_name,
                defaults={'icon': self.get_default_icon_for_feature(feature_name)}
            )

            if created and self.verbose:
                self.stdout.write(f"    –°–æ–∑–¥–∞–Ω–æ –Ω–æ–≤–æ–µ —É–¥–æ–±—Å—Ç–≤–æ: {feature_name}")

            # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å, –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç
            relation, created = PropertyFeatureRelation.objects.get_or_create(
                property=property_obj,
                feature=feature
            )

        if self.verbose:
            self.stdout.write(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —É–¥–æ–±—Å—Ç–≤: {len(feature_names)}")

    def get_default_icon_for_feature(self, feature_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∫–æ–Ω–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞"""
        icon_mapping = {
            '–ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä': 'fas fa-snowflake',
            'WiFi': 'fas fa-wifi',
            '–ë–∞—Å—Å–µ–π–Ω': 'fas fa-swimming-pool',
            '–ö—É—Ö–Ω—è': 'fas fa-utensils',
            '–ü–∞—Ä–∫–æ–≤–∫–∞': 'fas fa-parking',
            '–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞': 'fas fa-parking',
            '–î—É—à': 'fas fa-shower',
            '–õ–∏—Ñ—Ç': 'fas fa-elevator',
            '–í–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ': 'fas fa-video',
            '–û—Ö—Ä–∞–Ω–∞': 'fas fa-shield-alt',
            '–í–∞–Ω–Ω–∞': 'fas fa-bath',
            '–°–ø–æ—Ä—Ç–∑–∞–ª': 'fas fa-dumbbell',
            '–†–∞–±–æ—á–µ–µ –º–µ—Å—Ç–æ': 'fas fa-laptop',
        }
        return icon_mapping.get(feature_name, 'fas fa-check')

    def save_property_images(self, property_obj, image_urls):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–±—ä–µ–∫—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        if not image_urls:
            return

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        existing_images = PropertyImage.objects.filter(property=property_obj)
        existing_count = existing_images.count()

        if existing_count > 0:
            if self.verbose:
                self.stdout.write(f"  –£ –æ–±—ä–µ–∫—Ç–∞ —É–∂–µ –µ—Å—Ç—å {existing_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ‚Äî —É–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º")
            existing_images.delete()

        saved_count = 0
        for i, image_url in enumerate(image_urls):
            try:
                # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                response = self.session.get(image_url, timeout=30)
                if response.status_code != 200:
                    if self.verbose:
                        self.stdout.write(f"  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}: HTTP {response.status_code}")
                    continue

                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                img_temp = NamedTemporaryFile(delete=True)
                img_temp.write(response.content)
                img_temp.flush()

                # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL
                filename = os.path.basename(urlparse(image_url).path)
                if not filename or '.' not in filename:
                    filename = f"property_{property_obj.id}_{i}.jpg"

                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                property_image = PropertyImage.objects.create(
                    property=property_obj,
                    title=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}",
                    is_main=(i == 0),  # –ü–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–µ–ª–∞–µ–º –≥–ª–∞–≤–Ω—ã–º
                    order=i
                )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
                property_image.image.save(
                    filename,
                    File(img_temp),
                    save=True
                )

                saved_count += 1
                if self.verbose:
                    self.stdout.write(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}/{len(image_urls)}: {filename}")

            except Exception as e:
                self.stdout.write(self.style.WARNING(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_url}: {e}"))

        if saved_count > 0:
            self.stdout.write(self.style.SUCCESS(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ {property_obj.title}"))
